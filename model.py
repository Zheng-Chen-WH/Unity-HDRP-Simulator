import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.distributions import Normal
from utils import six_d_to_rot_mat, build_sincos_pos_embed

LOG_SIG_MAX = 2
LOG_SIG_MIN = -6
epsilon = 1e-6

def init_weights(m):
    """
    æ ¹æ®æ¨¡å—ç±»å‹åº”ç”¨Kaiming, Orthogonalç­‰æœ€ä½³å®è·µçš„æƒé‡åˆå§‹åŒ–ã€‚
    ä½¿ç”¨æ–¹æ³•: model.apply(init_weights)
    """
    if isinstance(m, nn.Conv2d):
        # Kaiming æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–ï¼Œä¸“ä¸ºReLUè®¾è®¡
        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
        if m.bias is not None:
            # åç½®é€šå¸¸åˆå§‹åŒ–ä¸º0
            nn.init.constant_(m.bias, 0)
            
    elif isinstance(m, (nn.BatchNorm2d, nn.LayerNorm)):
        # BNå±‚çš„gammaåˆå§‹åŒ–ä¸º1, betaåˆå§‹åŒ–ä¸º0
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)
        
    elif isinstance(m, nn.GRU):
        for name, param in m.named_parameters():
            if 'weight_ih' in name:
                # è¾“å…¥åˆ°éšè—å±‚çš„æƒé‡ï¼Œä½¿ç”¨Xavierå‡åŒ€åˆ†å¸ƒ
                nn.init.xavier_uniform_(param.data)
            elif 'weight_hh' in name:
                # éšè—å±‚åˆ°éšè—å±‚çš„æƒé‡ï¼Œä½¿ç”¨æ­£äº¤åˆå§‹åŒ–
                nn.init.orthogonal_(param.data)
            elif 'bias' in name:
                # åç½®åˆå§‹åŒ–ä¸º0
                param.data.fill_(0)
                
    elif isinstance(m, nn.Linear):
        # Kaiming æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–
        # a=0 è¡¨ç¤ºReLU, mode='fan_in' ä¿æŒå‰å‘ä¼ æ’­æ—¶æƒé‡çš„æ–¹å·®
        nn.init.kaiming_normal_(m.weight, a=0, mode='fan_in', nonlinearity='relu')
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)

class ResidualBlock(nn.Module):
    """å®šä¹‰ä¸€ä¸ªåŒ…å«ä¸¤ä¸ª3*3å·ç§¯å±‚çš„æ®‹å·®å—

    Args:
        in_channels: intè¾“å…¥é€šé“æ•°ï¼Œå¯¹RGBè€Œè¨€ä¸º3
        out_channels: è¾“å‡ºé€šé“æ•°ï¼ˆå·ç§¯æ ¸æ•°ï¼‰
        stride: å·ç§¯å—ç§»åŠ¨æ­¥å¹…
    """
    def __init__(self, in_channels, out_channels, stride=1):
        super(ResidualBlock, self).__init__()
        # nn.Conv2dç”¨äºæ‰§è¡ŒäºŒç»´å·ç§¯æ“ä½œ
        '''
        å·ç§¯æ ¸ä¸æ„Ÿå—é‡å†…çš„å€¼è¿›è¡ŒçŸ©é˜µç›¸ä¹˜å¹¶æ±‚å’Œï¼Œè¾“å‡ºä¸€ä¸ªå€¼
        in_channels: è¾“å…¥å›¾åƒçš„é€šé“æ•°ã€‚å¯¹äºç°åº¦å›¾åƒï¼Œin_channels ä¸º 1ã€‚å¯¹äºRGBå›¾åƒï¼Œin_channels ä¸º 3ã€‚
            å¦‚æœè¾“å…¥æ˜¯ä¸Šä¸€å±‚å·ç§¯çš„è¾“å‡ºï¼Œé‚£ä¹ˆ in_channels å°±æ˜¯ä¸Šä¸€å±‚çš„ out_channels
        out_channels: å·ç§¯å±‚è¾“å‡ºçš„ç‰¹å¾å›¾çš„æ•°é‡ï¼Œä¹Ÿå°±æ˜¯å·ç§¯æ ¸ï¼ˆæˆ–æ»¤æ³¢å™¨ï¼‰çš„æ•°é‡
        kernel_size: å·ç§¯æ ¸ï¼ˆæˆ–æ»¤æ³¢å™¨ï¼‰çš„å¤§å°ã€‚è®¾ç½®ä¸º 3ï¼Œè¡¨ç¤ºå·ç§¯æ ¸æ˜¯ä¸€ä¸ª 3x3 çš„æ­£æ–¹å½¢ã€‚
            ä¹Ÿå¯ä»¥ä½¿ç”¨ä¸€ä¸ªå…ƒç»„æ¥æŒ‡å®šéæ­£æ–¹å½¢çš„å·ç§¯æ ¸ï¼Œä¾‹å¦‚ (3, 5) è¡¨ç¤º 3 è¡Œ 5 åˆ—çš„å·ç§¯æ ¸ã€‚
        stride: å·ç§¯æ ¸åœ¨è¾“å…¥ç‰¹å¾å›¾ä¸Šæ»‘åŠ¨çš„æ­¥é•¿
            stride=1 (é»˜è®¤å€¼)ï¼Œå·ç§¯æ ¸æ¯æ¬¡ç§»åŠ¨ä¸€ä¸ªåƒç´ 
            stride=2ï¼Œå·ç§¯æ ¸æ¯æ¬¡ç§»åŠ¨ä¸¤ä¸ªåƒç´ ï¼Œå¯¼è‡´è¾“å‡ºç‰¹å¾å›¾çš„å°ºå¯¸å‡åŠï¼Œå¸¸ç”¨äºé™é‡‡æ ·
            å¯ä»¥æŒ‡å®šä¸€ä¸ªå…ƒç»„ (å¦‚ stride=(1, 2))ï¼Œè¡¨ç¤ºæ°´å¹³å’Œå‚ç›´æ–¹å‘çš„æ­¥é•¿ä¸åŒ
        padding: åœ¨è¾“å…¥ç‰¹å¾å›¾çš„è¾¹ç•Œå‘¨å›´æ·»åŠ çš„é›¶çš„æ•°é‡
            ä¸»è¦ç›®çš„æ˜¯ä¸ºäº†åœ¨å·ç§¯æ“ä½œä¸­ä¿ç•™è¾“å…¥ç‰¹å¾å›¾çš„ç©ºé—´å°ºå¯¸ï¼Œé˜²æ­¢è¾¹ç¼˜ä¿¡æ¯ä¸¢å¤±ï¼Œå¹¶ä½¿å¾—è¾“å‡ºç‰¹å¾å›¾çš„å°ºå¯¸ä¸è¾“å…¥ç‰¹å¾å›¾æ›´æ¥è¿‘æˆ–ç›¸åŒ
        bias: ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œè¡¨ç¤ºæ˜¯å¦åœ¨å·ç§¯æ“ä½œåæ·»åŠ åç½®
        '''
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)

        # åˆ›å»ºä¸€ä¸ªäºŒç»´æ‰¹å½’ä¸€åŒ–ï¼ˆBatch Normalizationï¼‰å±‚
        '''
        nn.BatchNorm2d å±‚ç´§è·Ÿåœ¨ nn.Conv2d å±‚ä¹‹åï¼Œnum_featuresåº”è¯¥ä¸å‰é¢ nn.Conv2d å±‚çš„ out_channels ç›¸åŒ¹é…
        BatchNorm2d å±‚ä¼šå¯¹è¾“å…¥æ•°æ®çš„æ¯ä¸ªé€šé“ç‹¬ç«‹åœ°è¿›è¡Œå½’ä¸€åŒ–æ“ä½œã€‚
        å¯¹äºæ¯ä¸ªæ‰¹æ¬¡ï¼ˆmini-batchï¼‰çš„è¾“å…¥æ•°æ®ï¼Œå®ƒä¼šè®¡ç®—æ¯ä¸ªé€šé“çš„å‡å€¼å’Œæ–¹å·®ï¼Œç„¶åä½¿ç”¨è¿™äº›ç»Ÿè®¡é‡æ¥å½’ä¸€åŒ–è¯¥é€šé“çš„æ•°æ®ï¼Œä½¿å…¶å‡å€¼ä¸º 0ï¼Œæ–¹å·®ä¸º 1ã€‚
        å®ƒè¿˜ä¼šå­¦ä¹ ä¸¤ä¸ªå¯è®­ç»ƒçš„å‚æ•°ï¼šç¼©æ”¾å› å­ğ›¾(gamma)å’Œåç§»å› å­ğ›½(beta)ï¼Œç”¨æ¥å¯¹å½’ä¸€åŒ–åçš„æ•°æ®è¿›è¡Œçº¿æ€§å˜æ¢ï¼Œä»¥æ¢å¤ç½‘ç»œçš„è¡¨è¾¾èƒ½åŠ›'''
        self.bn1 = nn.BatchNorm2d(out_channels)

        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        # å®šä¹‰ä¸€ä¸ªæ®‹å·®è·³è·ƒè¿æ¥ï¼ˆshortcut connectionï¼‰
        self.shortcut = nn.Sequential() # ä¸€ä¸ªç©ºçš„ nn.Sequential()èµ·åˆ°æ’ç­‰æ˜ å°„çš„ä½œç”¨ï¼Œå®ƒå°†è¾“å…¥ç›´æ¥ä¼ é€’åˆ°è¾“å‡º
        if stride != 1 or in_channels != out_channels: 
            '''
            ä¸ºäº†ä½¿è·³è·ƒè¿æ¥çš„è¾“å‡ºå°ºå¯¸ä¸ä¸»è·¯å¾„çš„è¾“å‡ºå°ºå¯¸åŒ¹é…ï¼Œè·³è·ƒè¿æ¥æœ¬èº«ä¹Ÿéœ€è¦è¿›è¡Œç›¸åº”çš„ç©ºé—´é™é‡‡æ ·
            1x1 å·ç§¯å±‚ï¼ˆä¹Ÿç§°ä¸ºé€ç‚¹å·ç§¯ï¼‰ï¼Œä¸»è¦ä½œç”¨ä¸æ˜¯æå–ç©ºé—´ç‰¹å¾ï¼Œè€Œæ˜¯ç”¨æ¥æ”¹å˜ç‰¹å¾å›¾çš„é€šé“æ•° (in_channels å˜ä¸º out_channels)
            strideä¸ if æ¡ä»¶ä¸­çš„ stride ä¿æŒä¸€è‡´ï¼Œå¦‚æœä¸»è·¯å¾„è¿›è¡Œäº†ç©ºé—´é™é‡‡æ ·ï¼Œ1x1å·ç§¯ä¹Ÿä¼šæ‰§è¡Œç›¸åŒçš„é™é‡‡æ ·ï¼Œç¡®ä¿è·³è·ƒè¿æ¥çš„è¾“å‡ºç©ºé—´å°ºå¯¸ä¸ä¸»è·¯å¾„çš„è¾“å‡ºåŒ¹é…
            è¿™é‡Œä¸è¿›è¡Œpaddingæ˜¯åŒ¹é…ä¸»è·¯çš„kernel=3ï¼Œå¦‚æœkernelè¾ƒå¤§æ—¶åœ¨è¿™é‡Œä¹Ÿéœ€è¦å¤„ç†paddingä»¥åŒ¹é…ä¸»è·¯ç‰¹å¾å›¾'''
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False), 
                nn.BatchNorm2d(out_channels)
            )

    def forward(self, x):
        out = F.leaky_relu(self.bn1(self.conv1(x))) # å¥½åƒleakyreluä¼šå¥½ä¸€ç‚¹
        out = self.bn2(self.conv2(out))
        out += self.shortcut(x)
        out = F.leaky_relu(out)
        return out

class ResNet(nn.Module):
    '''è‡ªå®šä¹‰ResNetï¼Œä¸»è¾“å‡ºä¸ºç‰¹å¾å‘é‡ï¼Œå¹¶å¸¦æœ‰ä¸€ä¸ªç”¨äºé¢„æµ‹ä½å§¿çš„è¾…åŠ©å¤´ã€‚
        
        ResNetç»“æ„åˆ†å±‚ä¸ºç¼–ç å™¨æ•´ä½“-é˜¶æ®µï¼ˆå¤„ç†çš„ç‰¹å¾å›¾é«˜å’Œå®½éƒ½ä¿æŒä¸å˜ï¼‰-æ®‹å·®å—-å·ç§¯å±‚

    Args:
        args:åŒ…å«æœ‰æ‰€æœ‰æ‰€éœ€å‚æ•°çš„å­—å…¸
    '''
    def __init__(self, args):
        super(ResNet, self).__init__()
        '''
        å‚è€ƒçœŸÂ·ResNetï¼Œç¬¬ä¸€å±‚æ˜¯size=7çš„å·ç§¯æ ¸ï¼Œpaddingä¸º3ï¼Œä½†æ˜¯è¿™æ ·è¾“å‡ºçš„ç‰¹å¾å›¾å°ºå¯¸æ˜¯å–å†³äºxå¥‡å¶æ€§çš„(x+1)/2
        ä¸€èˆ¬éƒ½æ˜¯å¥‡æ•°å¤§å°å·ç§¯æ ¸ï¼Œæœ‰ä¸ªæ˜ç¡®çš„ä¸­å¿ƒï¼Œæ‰€ä»¥stride=2çš„æƒ…å†µä¸‹è¾“å‡ºçš„å›¾åƒå°ºå¯¸ä¸€å®šä¸ç¡®å®š
        '''
        first_layer_dict = args["first_CNN_layer"]
        self.conv1 = nn.Conv2d(args["input_channels"], first_layer_dict["out_put_channel"],
                                kernel_size = first_layer_dict["kernel_size"], 
                                stride = first_layer_dict["stride"], padding = first_layer_dict["padding"], bias=False)
        self.bn1 = nn.BatchNorm2d(first_layer_dict["out_put_channel"])
        
        # å®šä¹‰ä¸€ä¸ªäºŒç»´æœ€å¤§æ± åŒ–å±‚ï¼Œé€šè¿‡åœ¨ä¸€ä¸ªå±€éƒ¨åŒºåŸŸï¼ˆç”± kernel_size å®šä¹‰ï¼‰å†…å–æœ€å¤§å€¼æ¥å¯¹è¾“å…¥ç‰¹å¾å›¾è¿›è¡Œä¸‹é‡‡æ ·ï¼ˆé™é‡‡æ ·ï¼‰
        '''
        é™ä½ç»´åº¦ï¼šå‡å°‘ç‰¹å¾å›¾çš„ç©ºé—´å°ºå¯¸ï¼Œä»è€Œå‡å°‘åç»­å±‚çš„è®¡ç®—é‡å’Œå‚æ•°æ•°é‡
        æå–ä¸»è¦ç‰¹å¾ï¼šä¿ç•™å±€éƒ¨åŒºåŸŸå†…æœ€æ˜¾è‘—çš„ç‰¹å¾ï¼ˆæœ€å¤§å€¼ï¼‰ï¼Œå¿½ç•¥ä¸é‡è¦çš„ç»†èŠ‚
        å¢å¼ºå¹³ç§»ä¸å˜æ€§ï¼šå³ä½¿è¾“å…¥ä¸­çš„ç‰¹å¾å‘ç”Ÿäº†è½»å¾®çš„å¹³ç§»ï¼Œç”±äºå–æœ€å¤§å€¼çš„æ“ä½œï¼Œè¾“å‡ºç‰¹å¾ä¹Ÿå¯èƒ½ä¿æŒä¸å˜ï¼Œè¿™æœ‰åŠ©äºæ¨¡å‹å¯¹ç‰¹å¾çš„ä½ç½®ä¸é‚£ä¹ˆæ•æ„Ÿ
        '''
        self.maxpool = nn.MaxPool2d(kernel_size = args["max_pool"]["kernel_size"],
                                     stride = args["max_pool"]["stride"], padding = args["max_pool"]["padding"])

        """ç”¨äºåŠ¨æ€æ„å»ºåŒ…å«è‹¥å¹²ä¸ªæ®‹å·®é˜¶æ®µçš„ResNet"""
        stages = []
        current_channels = first_layer_dict["out_put_channel"]  # åœ¨conv1å’Œmaxpoolä¹‹åçš„é€šé“æ•°

        # éå†æ¯ä¸ªé˜¶æ®µçš„é…ç½®
        for i, (num_blocks, out_channels) in enumerate(zip(args['block_counts'], args['channel_scales'])):
            layers = []
            '''
            æ¯ä¸ªé˜¶æ®µçš„ç¬¬ä¸€ä¸ªblockå¯èƒ½éœ€è¦æ”¹å˜æ­¥é•¿æ¥ä¸‹é‡‡æ ·
            é™¤äº†ç¬¬ä¸€ä¸ªé˜¶æ®µå¤–ï¼Œé€šè¿‡stride=2ä¸‹é‡‡æ ·ï¼Œç¼©å°ç‰¹å¾å›¾çš„å°ºå¯¸åŒæ—¶å¢åŠ ç‰¹å¾å›¾çš„é€šé“æ•°
            æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œä¸­éå¸¸å¸¸è§çš„æ¨¡å¼ï¼Œç”¨äºåœ¨ç½‘ç»œæ·±å±‚æå–æ›´é«˜çº§ã€æ›´æŠ½è±¡çš„ç‰¹å¾ï¼ŒåŒæ—¶å‡å°‘ç©ºé—´ç»´åº¦ä»¥èŠ‚çœè®¡ç®—é‡å’Œå‚æ•°'''
            stride = 2 if i > 0 else 1 # ç¬¬ä¸€ä¸ªstage(64->64)çš„strideä¸º1ï¼Œå…¶ä½™ä¸º2

            # æ·»åŠ è¯¥é˜¶æ®µçš„ç¬¬ä¸€ä¸ªblock
            layers.append(ResidualBlock(current_channels, out_channels, stride = stride))
            current_channels = out_channels  # æ›´æ–°å½“å‰é€šé“æ•°

            # æ·»åŠ è¯¥é˜¶æ®µå‰©ä½™çš„blocks
            for _ in range(1, num_blocks):
                layers.append(ResidualBlock(current_channels, out_channels, stride = 1))
            
            stages.append(nn.Sequential(*layers))
        
        self.stages =  nn.Sequential(*stages)

        # äºŒç»´è‡ªé€‚åº”å¹³å‡æ± åŒ–å±‚ï¼ŒæŒ‡å®šçš„æ˜¯ç›®æ ‡è¾“å‡ºå°ºå¯¸ï¼Œè€Œä¸æ˜¯æ ¸å¤§å°å’Œæ­¥é•¿ã€‚
        '''
        ç½‘ç»œä¼šæ ¹æ®è¾“å…¥ç‰¹å¾å›¾çš„å°ºå¯¸ï¼Œè‡ªåŠ¨è®¡ç®—å‡ºåˆé€‚çš„ kernel_size å’Œ stride æ¥è¾¾åˆ°æ‚¨æŒ‡å®šçš„ç›®æ ‡è¾“å‡ºå°ºå¯¸
        è®¾ç½® output_size=(1, 1) æ—¶ï¼Œnn.AdaptiveAvgPool2dä¼šå–è¾“å…¥ç‰¹å¾å›¾çš„æ‰€æœ‰åƒç´ çš„å¹³å‡å€¼ï¼Œä¸ºæ¯ä¸ªé€šé“ç”Ÿæˆä¸€ä¸ªå•ä¸€çš„å€¼
        ç”¨æ¥æ›¿ä»£ä¼ ç»Ÿçš„ã€åœ¨å·ç§¯å±‚ä¹‹åä½¿ç”¨çš„å…¨è¿æ¥å±‚'''
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))

        # æ˜¾å¼è¾“å‡ºç›¸å¯¹ä½å§¿çš„è¾…åŠ©è¾“å‡ºå¤´
        '''
        nn.Flattenå°†è¾“å…¥çš„å¤šç»´å¼ é‡ï¼ˆTensorï¼‰å±•å¹³ï¼ˆflattenï¼‰æˆä¸€ç»´å¼ é‡
        ä¿ç•™ç¬¬ä¸€ä¸ªç»´åº¦ï¼Œé€šå¸¸æ˜¯æ‰¹é‡å¤§å°ï¼Œç„¶åå°†æ‰€æœ‰åç»­ç»´åº¦ï¼ˆé€šé“ã€é«˜åº¦ã€å®½åº¦ç­‰ï¼‰åˆå¹¶ï¼ˆæˆ–å±•å¹³ï¼‰æˆä¸€ä¸ªå•ä¸€çš„ç»´åº¦
        è¿™é‡Œæ˜¯(batch_size, 512,1,1)è¢«è½¬æˆ(batch_size,512)'''
        self.aux_head = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),
            nn.Linear(args['channel_scales'][-1], 128), nn.ReLU(),
            nn.Linear(128, args["num_aux_output"])
        )
        
        sincos_time_vector = build_sincos_pos_embed(args["frames"], args["embed_dim"])
        # å°†æ—¶é—´ä½ç½®å‘é‡æ³¨å†Œä¸ºæ¨¡å‹çš„bufferï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå¯è®­ç»ƒçš„Parameter
        self.register_buffer('sincos_time_embed', sincos_time_vector)

    def forward(self, x):
        # åŸå§‹è¾“å…¥å½¢çŠ¶: (B, T, C, H, W)  (B=æ‰¹é‡å¤§å°, T=å¸§æ•°, C=é€šé“æ•°, H=é«˜åº¦, W=å®½åº¦)
        print(x.shape)
        B, T, C, H, W = x.shape

        # å°† (B, T, C, H, W) -> (B * T, C, H, W)
        '''
        å°†æ—¶é—´å’Œæ‰¹æ¬¡ç»´åº¦â€œå‹å¹³â€ (Flatten/Reshape)
        è®©ResNetä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰åºåˆ—ä¸­çš„æ‰€æœ‰å¸§ï¼Œå¦‚åŒä¸€ä¸ªè¶…å¤§çš„batch'''
        first_input = x.view(B * T, C, H, W)

        # å¹¶è¡ŒåŒ–æ­¥éª¤, GPUä¼šå¹¶è¡Œå¤„ç†è¿™ B*T å¼ å›¾ç‰‡ã€‚
        '''
        ä¸€æ¬¡æ€§é€šè¿‡ç‰¹å¾æå–å™¨ (Single Forward Pass)
        resnet_main_feat çš„å½¢çŠ¶ä¼šæ˜¯ (B * T, feat_dim)
        resnet_aux_pred çš„å½¢çŠ¶ä¼šæ˜¯ (B * T, 6)  (å‡è®¾6Då§¿æ€)'''
        x = F.relu(self.bn1(self.conv1(first_input)))
        x = self.maxpool(x)

        # é€šè¿‡æ‰€æœ‰åŠ¨æ€åˆ›å»ºçš„æ®‹å·®é˜¶æ®µ
        x = self.stages(x)
        aux_output = self.aux_head(x) # æœ€åä¸€ä¸ªé˜¶æ®µå‡ºæ¥ç›´æ¥å»è¾…åŠ©å¤´
        main_features = self.avgpool(x) # æœ€åä¸€ä¸ªé˜¶æ®µæ®‹å·®å—å‡ºæ¥ç»è¿‡å¹³å‡æ± åŒ–å½¢æˆä¸»ç‰¹å¾å‘é‡
        main_features = torch.flatten(main_features, 1)

        # æ¢å¤æ—¶é—´å’Œæ‰¹æ¬¡ç»´åº¦ï¼Œå°†è¾“å‡ºå˜å›åºåˆ—æ ¼å¼ï¼Œ(B * T, feat_dim) -> (B, T, feat_dim)
        main_features = main_features.view(B, T, -1) # -1 ä¼šè‡ªåŠ¨æ¨æ–­ä¸º feat_dim
        time_pos_embed = self.sincos_time_embed[:, :T, :]
        main_features_with_time_pos = main_features + time_pos_embed

        # æ•´ç†è¾…åŠ©ä»»åŠ¡çš„é¢„æµ‹åºåˆ—ï¼Œå°† (B * T, 6) -> (B, T, 6)
        aux_output = aux_output.view(B, T, -1) # -1 ä¼šè‡ªåŠ¨æ¨æ–­ä¸º 6
        
        return main_features, main_features_with_time_pos, aux_output # è¿”å›ä¸»ç‰¹å¾å’Œè¾…åŠ©å¤´çš„æ˜¾å¼è¾“å‡º

class VisionTransformer(nn.Module):
    """
    ç”¨äº1:1æ›¿æ¢ResNetçš„Transformeræ¨¡å—.
    è¿™ä¸€æ¨¡å—è¾“å…¥å•å¼ å›¾ç‰‡ï¼Œå¹¶è¾“å‡ºç‰¹å¾å‘é‡å’Œä¸€ä¸ªè¾…åŠ©è¾“å‡ºå¤´
    """
    def __init__(self, args):
        """
        Args: args:å­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹å†…å®¹ï¼š
                img_size (tuple): è¾“å…¥å›¾åƒå¤§å° (H, W).
                patch_size (int): ä¸€ä¸ªpatchè¾¹é•¿.
                input_channels (int): è¾“å…¥å›¾åƒé¢œè‰²é€šé“.
                num_aux_outputs (int): è¾…åŠ©è¾“å‡ºå¤´ç»´åº¦.
                embed_dim (int): transformerå†…éƒ¨ç»´åº¦(d_model).
                depth (int): transformerç¼–ç å™¨å±‚æ•°.
                num_heads (int): æ³¨æ„åŠ›å¤´æ•°.
                mlp_ratio (float): FFNéšè—å±‚å¤§å°æ¯”ä¾‹å› æ•°ï¼Œhidden_dimension = embed_dim * mlp_ratio
                dropout (float): Dropoutæ¯”ä¾‹.
        """
        super().__init__()
        self.embed_dim = args["embed_dim"]
 
        # å›¾åƒåµŒå…¥
        '''
        è¾“å…¥ï¼šä¸€å¼  (3, 224, 224) çš„å›¾åƒã€‚
            kernel_size=stride=patchsize (åˆ†å—)ï¼šå·ç§¯æ ¸å°†ä»¥patch_sizeçš„å¤§å°ï¼Œä¸é‡å åœ°åœ¨å›¾åƒä¸Šæ»‘åŠ¨ã€‚
            æ€»å…±ä¼šæ»‘åŠ¨(H/P)*(W/P)= HW/p^2=Næ¬¡ã€‚è¿™æ„å‘³ç€å®ƒä¼šä¾æ¬¡å¤„ç†Nä¸ªpatchã€‚
            in_channels=3, out_channels=embed_dim(çº¿æ€§æŠ•å°„)ï¼šåœ¨Nä¸ªpatchä½ç½®çš„æ¯ä¸€ä¸ªä½ç½®ä¸Šï¼Œ
            å·ç§¯å±‚éƒ½ä¼šç”¨å®ƒçš„embed_dimä¸ªæ»¤æ³¢å™¨å»å¤„ç†é‚£ä¸ªpatchï¼Œå¹¶è¾“å‡ºä¸€ä¸ªembed_dimç»´çš„å‘é‡ã€‚
        è¾“å‡ºï¼šå·ç§¯å±‚æœ€ç»ˆçš„è¾“å‡ºå¼ é‡ç»´åº¦æ˜¯ (embed_dim, H/P, W/P)ã€‚
        è¿™ä¸ªè¾“å‡ºã€éšåã€‘ä¼šè¢«å±•å¹³å’Œé‡æ’ï¼Œå˜æˆ (HW/p^2, embed_dim)ï¼Œå¾—åˆ°Transformer æ¨¡å‹æ‰€æœŸæœ›çš„è¾“å…¥æ ¼å¼ã€‚
            å·ç§¯æ“ä½œåœ¨ç°ä»£æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ˆå¦‚ PyTorch, TensorFlowï¼‰å’Œç¡¬ä»¶ï¼ˆGPUï¼‰ä¸Šæ˜¯é«˜åº¦ä¼˜åŒ–çš„ã€‚
            å°†â€œåˆ†å—+çº¿æ€§å˜æ¢â€è¿™ä¸¤æ­¥æ“ä½œç”¨ä¸€ä¸ªå•ç‹¬çš„ã€é«˜åº¦ä¼˜åŒ–çš„ Conv2d æ¥å®ç°å¯ä»¥å°†å¤šæ¬¡å†…å­˜è®¿é—®å’Œè®¡ç®—åˆå¹¶ä¸ºä¸€æ¬¡å¤§çš„å¹¶è¡Œè®¡ç®—ã€‚   
        '''
        self.patch_embed = nn.Conv2d(args["input_channels"], args["embed_dim"], 
                                     kernel_size = args["patch_size"], stride = args["patch_size"])

        # è®¡ç®—patchæ•°
        num_patches = (args["img_size"][0] // args["patch_size"]) * (args["img_size"][1] // args["patch_size"])

        # è®¾ç½®CLS Tokenå’Œä½ç½®å‘é‡
        self.cls_token = nn.Parameter(torch.zeros(1, 1, args["embed_dim"]))

        # sincosæ–¹å¼ç”Ÿæˆsincosä½ç½®å‘é‡
        sincos_pos_vector = build_sincos_pos_embed(num_patches + 1, args["embed_dim"])
        sincos_time_vector = build_sincos_pos_embed(args["frames"], args["embed_dim"])
        # å°†æ—¶ç©ºä½ç½®å‘é‡åˆ†åˆ«æ³¨å†Œä¸ºæ¨¡å‹çš„bufferï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå¯è®­ç»ƒçš„Parameter
        self.register_buffer('sincos_pos_embed', sincos_pos_vector)
        self.register_buffer('sincos_time_embed', sincos_time_vector)
        
        # ä½ç½®å‘é‡å¯å­¦ä¹ éƒ¨åˆ†ï¼Œä¸sincosç›¸åŠ å¾—åˆ°
        self.pos_embed_res = nn.Parameter(torch.zeros(1, num_patches + 1, args["embed_dim"]))
        
        self.pos_drop = nn.Dropout(p = args["dropout"])

        # ä½¿ç”¨PyTorchå®šä¹‰çš„Transformerç¼–ç å™¨
        encoder_layer = nn.TransformerEncoderLayer(
            d_model = args["embed_dim"],
            nhead = args["num_heads"],
            dim_feedforward = int(args["embed_dim"] * args["mlp_ratio"]), # FFNç»´åº¦
            dropout = args["dropout"], # dropout
            activation = args["activation"] , # æˆ–è€…'gelu'
            batch_first = args["batch_first"], # è®¾å®šè¾“å…¥å’Œè¾“å‡ºå¼ é‡çš„ç»´åº¦é¡ºåºä¸º(Batch, Seq, Dim)
            norm_first = args["norm_first"]   # Pre-Layer Normalizationï¼Œåœ¨è‡ªæ³¨æ„åŠ›å±‚å’ŒFFNä¹‹å‰è¿›è¡Œå±‚å½’ä¸€åŒ–ï¼Œèƒ½æ›´ç¨³å®šä¸€äº›
        )

        # å †å nå±‚transformer
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers = args["depth"])

        # æœ€ååšä¸€å±‚å½’ä¸€åŒ–
        self.norm = nn.LayerNorm(args["embed_dim"])

        # è¾…åŠ©å¤´ 
        self.aux_head = nn.Sequential(
            nn.Linear(args["embed_dim"], 128),
            nn.ReLU(),
            nn.Linear(128, args["num_aux_outputs"])
        )

    def forward(self, x):
        """
        ViTå‰å‘ä¼ æ’­.
        Args:
            x (torch.Tensor): è¾“å…¥å›¾åƒåºåˆ—å¼ é‡(B, T, C, H, W)
        Returns:
            main_features (torch.Tensor): å½¢å¦‚(B, T, embed_dim)çš„ç‰¹å¾å¼ é‡.
            è¾…åŠ©è¾“å‡ºaux_output (torch.Tensor): å½¢å¦‚(B, T, num_aux_outputs)çš„å¼ é‡.
        """
        # x.shape: (B, T, C, H, W)
        B, T, C, H, W = x.shape

        # ç©ºé—´ç‰¹å¾æå–
        x = x.view(B * T, C, H, W)
        # åµŒå…¥: (B * T, C, H, W) -> (B * T, D, H/P, W/P)
        x = self.patch_embed(x)
        
        # å±•å¹³å¹¶é‡æ’: (B * T, D, H/P, W/P) -> (B * T, N, D), Nä¸ºnum_patches
        x = x.flatten(2).transpose(1, 2)

        # å¢åŠ CLS Token: (B, N, D) -> (B, N+1, D)
        cls_tokens = self.cls_token.expand(B * T, -1, -1) # å¹¿æ’­
        x = torch.cat((cls_tokens, x), dim=1) # æ‹¼æ¥

        # ä¸ä½ç½®å‘é‡ç›¸åŠ ï¼Œä½ç½®å‘é‡å¯å­¦ä¹ 
        final_pos_embed = self.sincos_pos_embed + self.pos_embed_res
        x = x + final_pos_embed
        x = self.pos_drop(x)

        # transformerå¤„ç†
        x = self.transformer_encoder(x)
        
        # æœ€åä¸€æ¬¡layernorm
        x = self.norm(x)

        # ä¸»è¾“å‡ºæ˜¯[CLS] token, shape: (B*T, num_patches+1, embed_dim) -> (B*T, embed_dim)
        main_features = x[:, 0] # Shape: (B*T, D)

        # ä¸¤ç§æ¥è¾…åŠ©å¤´çš„æ–¹å¼ï¼Œä¸€ç§æ˜¯æ¥clsä»¥å¤–å¼ é‡ï¼Œä¸€ç§æ˜¯æ¥clsï¼Œå…ˆè¯•è¯•æ¥cls
        # aux_input = x[:, 1:].mean(dim=1) # Shape: (B, D)
        # aux_output = self.aux_head(aux_input)
        aux_output = self.aux_head(main_features)

        # æ¢å¤æ—¶é—´ç»´åº¦ï¼Œshape: (B*T, embed_dim) -> (B, T, embed_dim)
        main_features = main_features.view(B, T, -1)
        aux_output = aux_output.view(B, T, -1)

        # æ·»åŠ æ—¶é—´ä½ç½®ç¼–ç 
        # ä» buffer ä¸­å–å‡ºæ—¶é—´ç¼–ç ï¼Œå¹¶æˆªå–å½“å‰åºåˆ—é•¿åº¦ T
        time_pos_embed = self.sincos_time_embed[:, :T, :]
        main_features_with_time_pos = main_features + time_pos_embed

        return main_features, main_features_with_time_pos, aux_output

class TemporalTransformer(nn.Module):
    """
    ä¸€ä¸ªç”¨äºå¤„ç†å¸§åºåˆ—ç‰¹å¾çš„Transformerï¼Œæå–åŠ¨æ€ä¿¡æ¯ã€‚
    è¾“å…¥: ViTå¤„ç†åçš„å¸§ç‰¹å¾åºåˆ—ï¼Œå½¢çŠ¶ä¸º (B, T, D)ã€‚
    è¾“å‡º: 
        - main_output: è¾“å‡ºç‰¹å¾å‘é‡ã€‚
        - aux_output_dynamics: è¾…åŠ©ä»»åŠ¡è¾“å‡ºï¼Œç›¸å¯¹é€Ÿåº¦ã€è§’é€Ÿåº¦6Dä¿¡æ¯ã€‚
    """
    def __init__(self, args):
        super().__init__()
        self.embed_dim = args["embed_dim"]

        # å®šä¹‰æ‘˜è¦Tokenï¼Œç”¨äºæ±‡æ€»æ•´ä¸ªæ—¶é—´åºåˆ—çš„ä¿¡æ¯ï¼Œç”Ÿæˆæœ€ç»ˆçš„æ§åˆ¶å†³ç­–
        self.summary_token = nn.Parameter(torch.zeros(1, 1, args["embed_dim"]))

        # æ—¶é—´ä½ç½®ç¼–ç å·²ç»åœ¨ViTçš„è¾“å‡ºä¸­è¢«æ·»åŠ ï¼Œä¸éœ€è¦é‡å¤æ·»åŠ 
        # ä»ç„¶éœ€è¦ä¸€ä¸ªTransformer Encoderæ¥å¤„ç†è¿™ä¸ªåºåˆ—
        
        # æ—¶é—´Transformerç¼–ç å™¨å±‚
        temporal_encoder_layer = nn.TransformerEncoderLayer(
            d_model = args["embed_dim"],
            nhead = args["num_heads"],
            dim_feedforward = int(args["embed_dim"] * args["mlp_ratio"]),
            dropout = args["dropout"],
            activation = args["activation"],
            batch_first = args["batch_first"],
            norm_first = args["norm_first"]
        )


        self.input_projection = nn.Linear(args["input_dim"], args["embed_dim"])

        # æ—¶é—´Transformerç¼–ç å™¨ä¸»ä½“
        self.temporal_transformer_encoder = nn.TransformerEncoder(
            temporal_encoder_layer, 
            num_layers = args["depth"]
        )

        self.norm = nn.LayerNorm(args["embed_dim"])

        # å®šä¹‰è¾…åŠ©è¾“å‡ºå¤´ï¼Œç”¨äºé¢„æµ‹6DåŠ¨æ€ä¿¡æ¯ï¼ˆç›¸å¯¹é€Ÿåº¦+è§’é€Ÿåº¦ï¼‰
        self.aux_head_dynamics = nn.Sequential(
            nn.Linear(args["embed_dim"], 128),
            nn.ReLU(),
            nn.Linear(128, args["num_aux_outputs"]) # è¾“å‡ºè¾…åŠ©å¤´ç»´åº¦ä¸ªå€¼
        )

    def forward(self, input, x, hidden_state=None):
        # è¾“å…¥xçš„å½¢çŠ¶: (B, T, D)ï¼Œå³ViTè¾“å‡ºçš„ main_features_with_time_pos
        B = x.shape[0]
        # ç»´åº¦å¯¹é½
        x = self.input_projection(x)
        # åœ¨åºåˆ—çš„å¼€å¤´æ‹¼æ¥ä¸Šsummary Token
        '''
        ViTä¸­ï¼š
            ä¸ºäº†é«˜æ•ˆå¹¶è¡Œå¤„ç†å¤šå¼ å›¾ç‰‡ï¼Œå°†Bå’ŒTä¸¤ä¸ªç»´åº¦å±•å¹³ï¼Œä¼ªè£…æˆä¸€ä¸ªæ›´å¤§çš„æ‰¹æ¬¡ï¼›
            B*T ä¸ªç‹¬ç«‹çš„æ ·æœ¬çš„æ¯ä¸€å¼ éƒ½éœ€è¦ä¸€ä¸ª [CLS] Tokenæ¥æ±‡æ€»è‡ªå·±çš„ç©ºé—´ä¿¡æ¯
            ViT çš„è‡ªæ³¨æ„åŠ›æ˜¯åœ¨ä¸€å¼ å›¾ç‰‡å†…éƒ¨çš„patchesä¹‹é—´è¿›è¡Œçš„ï¼Œç›®çš„æ˜¯ç†è§£ç©ºé—´å…³ç³»ã€‚ä¸åŒå¸§çš„patchesä¹‹é—´åœ¨æ­¤é˜¶æ®µå®Œå…¨æ²¡æœ‰äº¤äº’
        Temporal Transformerä¸­ï¼š
            ç›®æ ‡ä¸ºç†è§£Tå¸§ç‰¹å¾ä¹‹é—´çš„åŠ¨æ€å…³ç³»ï¼Œå¹¶å°†æ•´ä¸ªåºåˆ—çš„åŠ¨æ€ä¿¡æ¯èåˆæˆä¸€ä¸ªå•ä¸€çš„ç‰¹å¾å‘é‡
            Tä¸æ˜¯æ‰¹æ¬¡çš„ä¸€éƒ¨åˆ†ï¼Œè€Œæ˜¯è¦å¤„ç†çš„åºåˆ—é•¿åº¦ã€‚è¿™æ­£æ˜¯TransformerEncoder (å½“ batch_first=True æ—¶) æ‰€æœŸæœ›çš„è¾“å…¥æ ¼å¼ã€‚
            ç”±äºç›®æ ‡æ˜¯ä¸ºé•¿åº¦ä¸ºTçš„åºåˆ—ç”Ÿæˆå•ä¸€æ‘˜è¦ã€‚å› æ­¤åªéœ€è¦ä¸ºæ¯ä¸ªbatché‡Œçš„æ ·æœ¬åœ¨å¼€å¤´é™„åŠ ä¸€ä¸ª summary_token
            TemporalTransformerçš„è‡ªæ³¨æ„åŠ›æ˜¯åœ¨ä¸€ä¸ªåºåˆ—å†…éƒ¨çš„Tä¸ªå¸§ä¹‹é—´è¿›è¡Œçš„ï¼Œç›®çš„æ˜¯ç†è§£æ—¶é—´å…³ç³»
        '''
        summary_tokens = self.summary_token.expand(B, -1, -1)
        x = torch.cat((summary_tokens, x), dim=1) # Shape: (B, T+1, D)

        # å°†æ‹¼æ¥åçš„åºåˆ—é€å…¥æ—¶é—´Transformerç¼–ç å™¨
        x = self.temporal_transformer_encoder(x)

        # åº”ç”¨å±‚å½’ä¸€åŒ–
        x = self.norm(x)

        # æå–ä¸åŒéƒ¨åˆ†çš„è¾“å‡º
        summary_token_output = x[:, 0, :]      # (B, D) -> ç”¨äºæœ€ç»ˆå†³ç­–
        frame_tokens_output = x[:, 1:, :]    # (B, T, D) -> åŒ…å«äº†ä¸Šä¸‹æ–‡ä¿¡æ¯çš„æ¯å¸§ç‰¹å¾

        # è®¡ç®—ä¸»è¾“å‡º
        main_output = summary_token_output

        # è®¡ç®—è¾…åŠ©è¾“å‡º (6DåŠ¨æ€ä¿¡æ¯)
        # avg_frame_features = frame_tokens_output.mean(dim=1) # Shape: (B, D)
        aux_output_dynamics = self.aux_head_dynamics(frame_tokens_output)

        return main_output, aux_output_dynamics, None

class GRU(nn.Module):
    """
    GRUæ¨¡å‹ã€‚
    - GRUå¤„ç†æ—¶åºä¿¡æ¯ï¼Œå¹¶æœ‰è¾…åŠ©å¤´é¢„æµ‹é€Ÿåº¦/è§’é€Ÿåº¦ã€‚
    - æœ€ç»ˆè¾“å‡ºä¸€ä¸ªèåˆæ—¶ç©ºä¿¡æ¯çš„ç‰¹å¾å‘é‡ã€‚
    """
    def __init__(self, args):
        """
        Args:
            resnet_aux_outputs (int): ResNetè¾…åŠ©å¤´è¾“å‡ºç»´åº¦ (ä¾‹å¦‚: 6ä¸ªä½å§¿å‚æ•°)
            gru_hidden_dim (int): GRUéšè—å±‚ç»´åº¦ï¼ˆç‰¹å¾å‘é‡ç»´åº¦ï¼‰
            gru_aux_outputs (int): GRUè¾…åŠ©å¤´è¾“å‡ºæ•°é‡ (ä¾‹å¦‚: 6ä¸ªé€Ÿåº¦/è§’é€Ÿåº¦å‚æ•°)
        """
        super(GRU, self).__init__()
        
        # GRUçš„è¾“å…¥ç»´åº¦ = å›¾åƒä¸»ç‰¹å¾ + å¤–éƒ¨åŠ¨æ€ç‰¹å¾ï¼Œæš‚æ—¶å…ˆåªæœ‰å›¾åƒ
        gru_input_dim = args["input_dim"] # + external_dynamic_features
        
        # GRUå¤„ç†æ—¶åºè¾“å‡ºæ—¶åºä¿¡æ¯
        '''
        input_sizeæ˜¯è¾“å…¥ç‰¹å¾çš„ç»´åº¦ï¼Œå³å¯¹äºåºåˆ—ä¸­çš„æ¯ä¸ªæ—¶é—´æ­¥ï¼Œè¾“å…¥åˆ° GRU å•å…ƒçš„æ•°æ®çš„ç‰¹å¾æ•°é‡
        hidden_sizeæ˜¯éšè—çŠ¶æ€ (hidden state) çš„ç»´åº¦ã€‚
            GRU å•å…ƒåœ¨æ¯ä¸ªæ—¶é—´æ­¥è®¡ç®—å¹¶æ›´æ–°ä¸€ä¸ªéšè—çŠ¶æ€ï¼Œhidden_size å®šä¹‰äº†è¿™ä¸ªéšè—çŠ¶æ€å‘é‡çš„é•¿åº¦
        num_layersæ˜¯å †å çš„ GRU å±‚æ•°ã€‚
            å¦‚æœ num_layers > 1ï¼Œé‚£ä¹ˆ GRU ç½‘ç»œå°†ç”±å¤šä¸ª GRU å±‚å †å è€Œæˆã€‚
            ç¬¬ä¸€ä¸ª GRU å±‚çš„è¾“å…¥æ˜¯åŸå§‹åºåˆ—æ•°æ®ã€‚éšåçš„æ¯ä¸ª GRU å±‚çš„è¾“å…¥æ˜¯å‰ä¸€ä¸ª GRU å±‚çš„è¾“å‡ºåºåˆ—ã€‚
            è¿™ç§å †å ç»“æ„å¯ä»¥å¸®åŠ©æ¨¡å‹å­¦ä¹ æ›´å¤æ‚ã€æ›´é«˜å±‚æ¬¡çš„æ—¶é—´ä¾èµ–å…³ç³»
        batch_firstæ˜¯ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œç”¨äºæŒ‡å®šè¾“å…¥å’Œè¾“å‡ºå¼ é‡çš„ç»´åº¦é¡ºåºã€‚
            batch_first=Trueï¼Œé‚£ä¹ˆè¾“å…¥å’Œè¾“å‡ºå¼ é‡çš„å½¢çŠ¶å°†æ˜¯ (batch, seq_len, features)
        dropout é™¤æœ€åä¸€å±‚ä¹‹å¤–çš„ GRU å±‚è¾“å‡ºçš„ Dropout æ¦‚ç‡ã€‚
            Dropout æ˜¯ä¸€ç§æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå®ƒä¼šéšæœºåœ°â€œå…³é—­â€ä¸€éƒ¨åˆ†ç¥ç»å…ƒçš„è¾“å‡ºã€‚
            Dropout åªåº”ç”¨äºå †å  GRU å±‚ä¹‹é—´çš„è¿æ¥ï¼Œè€Œä¸ä¼šåº”ç”¨äº GRU å•å…ƒå†…éƒ¨çš„å¾ªç¯è¿æ¥ã€‚
        ã€å…³äºGRUçš„ä¸¤ä¸ªé—¨ã€‘PyTorch ä¼šè‡ªåŠ¨åœ¨å†…éƒ¨åˆ›å»ºå®ç°è¿™ä¸¤ä¸ªé—¨æ‰€éœ€çš„æ‰€æœ‰æƒé‡çŸ©é˜µå’Œåç½®é¡¹
        '''
        self.gru = nn.GRU(
            input_size = gru_input_dim,
            hidden_size = args["gru_hidden_dim"],
            num_layers = args["layer_num"],
            batch_first = args["batch_first"],
            dropout = args["drop_out"] if args["layer_num"] > 1 else 0
        )
        
        # GRUçš„è¾…åŠ©å¤´: ç”¨äºæ˜¾å¼é¢„æµ‹é€Ÿåº¦/è§’é€Ÿåº¦ï¼Œå®ƒä½œç”¨äºGRUçš„æ•´ä¸ªè¾“å‡ºåºåˆ—ï¼Œä»¥å¾—åˆ°æ¯ä¸ªæ—¶é—´æ­¥çš„é¢„æµ‹
        self.gru_aux_head = nn.Sequential(
            nn.Linear(args["gru_hidden_dim"], 128),
            nn.ReLU(),
            nn.Linear(128, args["aux_out_dim"])
        )

    def forward(self, input, input_with_time, hidden_state=None):
        """
        Args:
            image_sequence (Tensor): å½¢çŠ¶ä¸º (Batchæ‰¹é‡å¤§å°, Timeå¸§æ•°, Channelsé€šé“æ•°, Heighté«˜åº¦, Widthå®½åº¦) çš„å›¾åƒåºåˆ—
        
        è¿”å›:
            ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«ï¼š
            - final_feature_vector (Tensor): GRUæœ€åçš„éšè—çŠ¶æ€, å½¢çŠ¶ä¸º (B, H_gru)
            - resnet_aux_predictions (Tensor): ResNetçš„å§¿æ€é¢„æµ‹, å½¢çŠ¶ä¸º (B, T, F_pose)
            - gru_aux_predictions (Tensor): GRUçš„é€Ÿåº¦é¢„æµ‹, å½¢çŠ¶ä¸º (B, T, F_vel)
        """
        
        # GRUå¤„ç†æ•´ä¸ªåºåˆ—
        '''
        å°† gru_inputs_sequence (å½¢çŠ¶ä¸º (B, T, C')) ä¼ é€’ç»™ self.gru æ—¶ï¼ŒPyTorch çš„ nn.GRU æ¨¡å—ä¼šåœ¨å†…éƒ¨è‡ªåŠ¨åœ°ã€é«˜æ•ˆåœ°å¾ªç¯ T æ¬¡ã€‚
        æ¯æ¬¡å¾ªç¯ä¸­ï¼Œå®ƒä¼šå–å‡ºåºåˆ—ä¸­çš„ä¸€ä¸ªæ—¶é—´æ­¥ (t) çš„æ‰€æœ‰æ‰¹æ¬¡æ•°æ® (gru_inputs_sequence[:, t, :])ï¼Œå¹¶ä¸å½“å‰çš„éšè—çŠ¶æ€ä¸€èµ·ï¼Œè®¡ç®—å‡ºä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ã€‚
        è¿™ä¸ªå†…éƒ¨å¾ªç¯æ˜¯é«˜åº¦ä¼˜åŒ–çš„ï¼Œé€šå¸¸é€šè¿‡ C++ æˆ– CUDA å®ç°ï¼Œæ¯” Python å¾ªç¯è¦é«˜æ•ˆå¾—å¤š
        gru_output_sequence æ˜¯ GRU åœ¨æ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºï¼ˆé€šå¸¸æ˜¯éšè—çŠ¶æ€ï¼‰ã€‚å½¢çŠ¶æ˜¯ (B, T, gru_hidden_dim)ï¼ŒåŒ…å«äº†åºåˆ—ä¸­æ¯ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€è¾“å‡ºã€‚
        last_hidden_state æ˜¯ GRU æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼Œå½¢çŠ¶æ˜¯ (num_layers * num_directions, B, gru_hidden_dim)ã€‚
        å¦‚æœæ˜¯å•å‘ GRU, åˆ™å½¢çŠ¶ä¸º (num_layers, B, gru_hidden_dim)ã€‚
        '''
        
        gru_output_sequence, last_hidden_state = self.gru(input, hidden_state)

        # GRUçš„è¾…åŠ©å¤´ï¼Œå¯¹æ¯ä¸€å¸§è¿›è¡Œæ˜¾å¼çš„é€Ÿåº¦/è§’é€Ÿåº¦é¢„æµ‹ï¼Œï¼ˆB,T,6ï¼‰
        gru_aux_predictions = self.gru_aux_head(gru_output_sequence)
        
        # æœ€ç»ˆçš„èåˆæ—¶ç©ºç‰¹å¾å‘é‡ (å–æœ€åä¸€å±‚çš„æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€)
        final_feature_vector = last_hidden_state[-1, :, :]
        return final_feature_vector, gru_aux_predictions, last_hidden_state


def mlp(sizes, activation, output_activation=nn.Identity):
    '''
    ç”Ÿæˆç½‘ç»œä¸”å…è®¸çµæ´»ä¿®æ”¹ï¼Œä½†å…¨éƒ½æ˜¯å…¨è¿æ¥å±‚ï¼Œå…¶ä¸­sizeå¯ä»¥æ˜¯ä¸€ä¸²åºåˆ—ï¼Œæ¯ä¸ªå…ƒç´ éƒ½æè¿°å¤§å°ï¼›åŒæ—¶jå’Œj+1åœ¨å¾ªç¯ä¸­è‡ªåŠ¨ç¡®ä¿ç›¸ä¹˜æ—¶è¡Œæ•°åˆ—æ•°ç›¸ç­‰
    nn.Identity æ„å‘³ç€ç½‘ç»œçš„è¾“å‡ºå±‚å°†åº”ç”¨æ’ç­‰æ˜ å°„ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œå³è¾“å‡ºå€¼ä¸è¾“å…¥å€¼å®Œå…¨ä¸€è‡´ï¼Œæ²¡æœ‰ç»è¿‡ä»»ä½•å˜æ¢
    çµæ´»ç”¨æ˜Ÿå·è§£åŒ…
    nn.Linear(a, b) ã€ä¸æ˜¯ä¸€ä¸ªå•çº¯çš„å…¨è¿æ¥å±‚ã€‘æ˜¯ PyTorch ä¸­çš„ä¸€ä¸ªçº¿æ€§å±‚ï¼ˆlinear layerï¼‰çš„æ„é€ å‡½æ•°ã€‚å®ƒåˆ›å»ºäº†ä¸€ä¸ªå°†è¾“å…¥ç‰¹å¾æ˜ å°„åˆ°è¾“å‡ºç‰¹å¾çš„çº¿æ€§å˜æ¢ã€‚
    nn.Linear(a, b) æ¥å—è¡¨ç¤ºè¾“å…¥ç‰¹å¾çš„ç»´åº¦aå’Œè¾“å‡ºç‰¹å¾çš„ç»´åº¦bï¼Œçº¿æ€§å±‚çš„ä½œç”¨æ˜¯é€šè¿‡å­¦ä¹ ä¸€ç»„æƒé‡å’Œåç½®ï¼Œå°†è¾“å…¥ç‰¹å¾è¿›è¡Œçº¿æ€§å˜æ¢ï¼Œå¾—åˆ°è¾“å‡ºç‰¹å¾ã€‚
    output = input * weight^T + bias
    å…¶ä¸­ï¼Œinput æ˜¯è¾“å…¥ç‰¹å¾ï¼Œweight æ˜¯å½¢çŠ¶ä¸º (b, a) çš„æƒé‡çŸ©é˜µï¼Œbias æ˜¯å½¢çŠ¶ä¸º (b,) çš„åç½®é¡¹ã€‚^T è¡¨ç¤ºæƒé‡çŸ©é˜µçš„è½¬ç½®ã€‚
    ''' 
    
    layers = []
    for j in range(len(sizes)-1):
        act = activation if j < len(sizes)-2 else output_activation
        # è¿˜æ˜¯ä¼šæ‰§è¡Œn-1æ¬¡ï¼Œä½†å¾ªç¯æœ€åä¸€æ¬¡ï¼ˆj=n-2ï¼‰æ—¶æ¿€æ´»å‡½æ•°æ˜¯æ’ç­‰æ˜ å°„
        layers += [nn.Linear(sizes[j], sizes[j+1]), act()]
    return nn.Sequential(*layers)

class GaussianPolicy(nn.Module):
    def __init__(self, args):
        super(GaussianPolicy, self).__init__()
        
        # å®šä¹‰ç¬¬ä¸€æ¨¡å—
        if args['first_module'] == "ResNet":
            # ResNeté€å¸§æå–ç‰¹å¾
            self.image_feature_extractor = ResNet(args['ResNet'])
        elif args['first_module'] == "ViT":
            # Transformeré€å¸§æå–ç‰¹å¾
            self.image_feature_extractor = VisionTransformer(args['ViT'])

        # å®šä¹‰ç¬¬äºŒæ¨¡å—
        if args['second_module'] == "GRU":
            self.dynamic_feature_extractor = GRU(args['GRU'])
        elif args['second_module'] == "TempT":
            self.dynamic_feature_extractor = TemporalTransformer(args["TemporalTransformer"])
        

        MLP_dict = args['MLP']
        # åœ¨æ‹¼æ¥åã€MLPå‰åŠ å…¥å½’ä¸€åŒ–å±‚LayerNorm
        concatenated_dim = MLP_dict["input_feature_dim"] + MLP_dict["mlp_state_dim"] # featureç»´åº¦+stateç»´åº¦
        # self.concat_norm = nn.LayerNorm(concatenated_dim)

        self.mlp_network=mlp([concatenated_dim] + list(MLP_dict["hidden_size"]), MLP_dict["activation"], MLP_dict["activation"]) #ç‰¹å¾å‘é‡+ç›®æ ‡ä½ç½®+å¾€æœŸåŠ¨ä½œ
        self.mu_layer = nn.Linear(MLP_dict["hidden_size"][-1], args["action_dim"])
        # ç”Ÿæˆmuçš„å±‚
        self.log_std_layer = nn.Linear(MLP_dict["hidden_size"][-1], args["action_dim"])

        # åŠ¨ä½œç¼©æ”¾ï¼Œè¿™é‡Œåœ¨å¤–éƒ¨è§£å†³ï¼Œé¿å…åŠ¨ä½œç›¸å·®å¤ªå°
        self.action_scale = torch.FloatTensor([
                (args["scaled_max_action"] - args["scaled_min_action"]) / 2.])
        self.action_bias = torch.FloatTensor([
                (args["scaled_max_action"] + args["scaled_min_action"]) / 2.])
        
        # æ‰“å°è¾…åŠ©å¤´ç»“æœ
        self.print_aux_output = args['print_aux_output']

    def forward(self, img_sequence, state, hidden_state=None):

        first_main_feat, first_main_feat_with_time, first_aux_pred = self.image_feature_extractor(img_sequence)

        # è¾“å…¥åˆ°åŠ¨æ€åºåˆ—æ¨¡å—
        features, second_aux_pred, new_hidden_state = self.dynamic_feature_extractor.forward(first_main_feat, first_main_feat_with_time, hidden_state)  # æå–ç‰¹å¾å¼ é‡
        concatenated_input = torch.cat([features, state],1) # æ‹¼æ¥ç‰¹å¾å¼ é‡å’ŒçŠ¶æ€
        
        # å…ˆè¿›è¡Œå±‚å½’ä¸€åŒ–
        # normalized_input = self.concat_norm(concatenated_input)

        # æ£€æŸ¥normalized_inputçš„é‡çº§
        x = self.mlp_network(concatenated_input)
        # print(f"normalized input:{normalized_input}")
        mean = self.mu_layer(x)
        log_std = self.log_std_layer(x)
        log_std = torch.clamp(log_std, min=LOG_SIG_MIN, max=LOG_SIG_MAX)
        return mean, log_std, first_aux_pred, second_aux_pred, new_hidden_state

    def sample(self, img_sequence, state, hidden_state=None):
        mean, log_std, resnet_output, gru_output, new_hidden_state = self.forward(img_sequence, state, hidden_state)
        # print(f"mean before tanh:{mean}")
        std = torch.exp(log_std)
        # print(std)
        normal = Normal(mean, std)
        x_t = normal.rsample() # é‡å‚æ•°åŒ–
        # ã€ä»¥ä¸‹æ–¹æ¡ˆæ˜¯ä»£ç ä½œè€…è‡ªå·±çš„æ–¹æ¡ˆï¼Œå…ˆå¾—åˆ°tanhåŠ¨ä½œå†å¯¹è¿™ä¸€åŠ¨ä½œæ±‚logã€‘
        y_t = torch.tanh(x_t) 
        action = y_t * self.action_scale + self.action_bias #ä¸æ˜¯é‡å‚æ•°åŒ–ï¼Œåªæ˜¯å•çº¯æŠŠå€¼è°ƒæ•´åˆ°åŠ¨ä½œç©ºé—´èŒƒå›´å†…
        log_prob = normal.log_prob(x_t)
        # Enforcing Action Bound
        log_prob -= torch.log((1 - y_t.pow(2)) + epsilon)
        log_prob -= torch.log(self.action_scale)  # æ·»åŠ Scalingé›…å¯æ¯” 
        # åŸè®ºæ–‡(21)å¼
        #log_prob -= torch.log(self.action_scale * (1 - y_t.pow(2)) + epsilon) #åŸè®ºæ–‡ä¸­å…¬å¼ï¼Œä½†æ˜¯å¤šäº†ä¸ªaction_scale
        log_prob = log_prob.sum(1, keepdim=True)
        mean = torch.tanh(mean) * self.action_scale + self.action_bias
        
        # æ‰“å°è¾…åŠ©å¤´è¾“å‡ºç»“æœ
        if self.print_aux_output:
            print(f"pred distance:", resnet_output[..., 0:3])
            pred_rot_6d_flat = resnet_output[..., 3:9].reshape(-1, 6)
            R_pred_flat = six_d_to_rot_mat(pred_rot_6d_flat)
            print(f"pred attitude:", R_pred_flat)
            print(f"pred velocity:", gru_output[..., 0:3])
            print(f"pred angular:", gru_output[..., 3:6])
            print("-------------------------------------------------------")
            
        return action, log_prob, mean, std, resnet_output, gru_output, new_hidden_state # è¾…åŠ©å¤´è¾“å‡ºåˆ†åˆ«æ˜¯ï¼ˆB,T,9ï¼‰å’Œï¼ˆB,T,6ï¼‰

    def to(self, device):
        self.action_scale = self.action_scale.to(device)
        self.action_bias = self.action_bias.to(device)
        return super(GaussianPolicy, self).to(device)

class QNetwork(nn.Module):
    """
    åˆ›å»ºåŒQç½‘ç»œ
    Args:
        critic_argsï¼šåŒ…å«å…¨éƒ¨å‚æ•°çš„å­—å…¸ï¼Œéœ€è¦åŒ…æ‹¬çŠ¶æ€ç»´åº¦ã€åŠ¨ä½œç»´åº¦ã€éšè—å±‚åˆ—è¡¨ã€æ¿€æ´»å‡½æ•°

    Returns:
        ä¸¤ä¸ªQç½‘ç»œåˆ†åˆ«è®¡ç®—çš„Q1ã€Q2 
    """
    def __init__(self, critic_args):
        super(QNetwork, self).__init__()
        #torch.manual_seed(42) #æ‰€æœ‰éšæœºæ•°ç§å­éƒ½ç”¨42
        # Q1 architecture
        self.Q_network_1=mlp([critic_args["state_dim"] + critic_args["action_dim"]] + list(critic_args["hidden_size"]) + [1],
                              critic_args["activation"])
        # nn.init.uniform_(self.Q_network_2[-1].weight, -1e-3, 1e-3)

        # Q2 architecture
        self.Q_network_2=mlp([critic_args["state_dim"] + critic_args["action_dim"]] + list(critic_args["hidden_size"]) + [1],
                              critic_args["activation"])

    def forward(self, state, action):
        xu = torch.cat([state, action], 1)
        x1 = self.Q_network_1(xu)
        x2 = self.Q_network_2(xu)
        
        return x1, x2

class ValueNetwork(nn.Module):
    """
    PPOéœ€è¦çš„Value Network (Critic)ï¼Œä¼°è®¡çŠ¶æ€ä»·å€¼ V(s)ã€‚
    ç»“æ„ä¸Šæ¨¡ä»¿ model.py ä¸­çš„ QNetworkï¼Œä½†è¾“å…¥ä»…ä¸º stateã€‚
    """
    def __init__(self, args):
        super(ValueNetwork, self).__init__()
        # args åŒ…å« state_dim, hidden_sizes, activation
        # è¿™é‡Œå¤ç”¨ model.py ä¸­çš„ mlp æ„å»ºå‡½æ•°
        self.v_net = mlp(
            [args['state_dim']] + args['hidden_size'] + [1],
            activation=args['activation']
        )
        
    def forward(self, state):
        return self.v_net(state)